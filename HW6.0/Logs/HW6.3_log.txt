Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 32, 32, 16)        448       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 16, 16, 32)        4640      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 8, 8, 16)          4624      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 8)           1160      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 8)           0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 2, 2, 8)           584       
_________________________________________________________________
up_sampling2d (UpSampling2D) (None, 4, 4, 8)           0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 4, 4, 16)          1168      
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 8, 8, 16)          0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 8, 8, 32)          4640      
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 16, 16, 16)        4624      
_________________________________________________________________
up_sampling2d_3 (UpSampling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 32, 32, 3)         435       
=================================================================
Total params: 22,323
Trainable params: 22,323
Non-trainable params: 0
_________________________________________________________________
CIFAR10 shape:  (50000, 32, 32, 3)
CIFAR10 test shape:  (10000, 32, 32, 3)
Epoch 1/100
50/50 - 10s - loss: 0.6693 - acc: 0.4413 - val_loss: 0.6404 - val_acc: 0.4182
Epoch 2/100
50/50 - 9s - loss: 0.6299 - acc: 0.4376 - val_loss: 0.6235 - val_acc: 0.4251
Epoch 3/100
50/50 - 9s - loss: 0.6202 - acc: 0.4441 - val_loss: 0.6182 - val_acc: 0.4467
Epoch 4/100
50/50 - 9s - loss: 0.6162 - acc: 0.4518 - val_loss: 0.6156 - val_acc: 0.4568
Epoch 5/100
50/50 - 9s - loss: 0.6136 - acc: 0.4526 - val_loss: 0.6140 - val_acc: 0.4616
Epoch 6/100
50/50 - 10s - loss: 0.6115 - acc: 0.4563 - val_loss: 0.6113 - val_acc: 0.4454
Epoch 7/100
50/50 - 9s - loss: 0.6098 - acc: 0.4556 - val_loss: 0.6108 - val_acc: 0.4625
Epoch 8/100
50/50 - 9s - loss: 0.6088 - acc: 0.4594 - val_loss: 0.6090 - val_acc: 0.4591
Epoch 9/100
50/50 - 9s - loss: 0.6080 - acc: 0.4607 - val_loss: 0.6090 - val_acc: 0.4577
Epoch 10/100
50/50 - 9s - loss: 0.6072 - acc: 0.4642 - val_loss: 0.6072 - val_acc: 0.4633
Epoch 11/100
50/50 - 9s - loss: 0.6069 - acc: 0.4676 - val_loss: 0.6066 - val_acc: 0.4706
Epoch 12/100
50/50 - 9s - loss: 0.6058 - acc: 0.4699 - val_loss: 0.6060 - val_acc: 0.4733
Epoch 13/100
50/50 - 9s - loss: 0.6054 - acc: 0.4750 - val_loss: 0.6054 - val_acc: 0.4786
Epoch 14/100
50/50 - 9s - loss: 0.6053 - acc: 0.4814 - val_loss: 0.6049 - val_acc: 0.4914
Epoch 15/100
50/50 - 9s - loss: 0.6036 - acc: 0.4943 - val_loss: 0.6044 - val_acc: 0.5015
Epoch 16/100
50/50 - 9s - loss: 0.6029 - acc: 0.5130 - val_loss: 0.6027 - val_acc: 0.5233
Epoch 17/100
50/50 - 9s - loss: 0.6022 - acc: 0.5306 - val_loss: 0.6020 - val_acc: 0.5369
Epoch 18/100
50/50 - 9s - loss: 0.6014 - acc: 0.5440 - val_loss: 0.6020 - val_acc: 0.5490
Epoch 19/100
50/50 - 9s - loss: 0.6003 - acc: 0.5534 - val_loss: 0.6027 - val_acc: 0.5576
Epoch 20/100
50/50 - 9s - loss: 0.6000 - acc: 0.5598 - val_loss: 0.6004 - val_acc: 0.5641
Epoch 21/100
50/50 - 9s - loss: 0.6014 - acc: 0.5620 - val_loss: 0.6016 - val_acc: 0.5673
Epoch 22/100
50/50 - 9s - loss: 0.5986 - acc: 0.5674 - val_loss: 0.5988 - val_acc: 0.5704
Epoch 23/100
50/50 - 9s - loss: 0.5986 - acc: 0.5704 - val_loss: 0.6015 - val_acc: 0.5723
Epoch 24/100
50/50 - 9s - loss: 0.5979 - acc: 0.5729 - val_loss: 0.5980 - val_acc: 0.5764
Epoch 25/100
50/50 - 9s - loss: 0.5974 - acc: 0.5758 - val_loss: 0.5980 - val_acc: 0.5757
Epoch 26/100
50/50 - 9s - loss: 0.5972 - acc: 0.5777 - val_loss: 0.5976 - val_acc: 0.5815
Epoch 27/100
50/50 - 9s - loss: 0.5974 - acc: 0.5787 - val_loss: 0.5988 - val_acc: 0.5845
Epoch 28/100
50/50 - 9s - loss: 0.5967 - acc: 0.5812 - val_loss: 0.5968 - val_acc: 0.5833
Epoch 29/100
50/50 - 9s - loss: 0.5975 - acc: 0.5818 - val_loss: 0.5968 - val_acc: 0.5824
Epoch 30/100
50/50 - 9s - loss: 0.5957 - acc: 0.5838 - val_loss: 0.5970 - val_acc: 0.5877
Epoch 31/100
50/50 - 9s - loss: 0.5964 - acc: 0.5847 - val_loss: 0.5962 - val_acc: 0.5908
Epoch 32/100
50/50 - 9s - loss: 0.5965 - acc: 0.5854 - val_loss: 0.5964 - val_acc: 0.5932
Epoch 33/100
50/50 - 9s - loss: 0.5952 - acc: 0.5867 - val_loss: 0.5969 - val_acc: 0.5934
Epoch 34/100
50/50 - 9s - loss: 0.5959 - acc: 0.5881 - val_loss: 0.5962 - val_acc: 0.5913
Epoch 35/100
50/50 - 9s - loss: 0.5951 - acc: 0.5893 - val_loss: 0.5958 - val_acc: 0.5909
Epoch 36/100
50/50 - 10s - loss: 0.5951 - acc: 0.5902 - val_loss: 0.5956 - val_acc: 0.5905
Epoch 37/100
50/50 - 10s - loss: 0.5950 - acc: 0.5913 - val_loss: 0.5958 - val_acc: 0.5927
Epoch 38/100
50/50 - 9s - loss: 0.5950 - acc: 0.5919 - val_loss: 0.5953 - val_acc: 0.5935
Epoch 39/100
50/50 - 9s - loss: 0.5947 - acc: 0.5929 - val_loss: 0.5958 - val_acc: 0.6005
Epoch 40/100
50/50 - 10s - loss: 0.5946 - acc: 0.5936 - val_loss: 0.5964 - val_acc: 0.5991
Epoch 41/100
50/50 - 10s - loss: 0.5943 - acc: 0.5943 - val_loss: 0.5962 - val_acc: 0.5930
Epoch 42/100
50/50 - 10s - loss: 0.5942 - acc: 0.5952 - val_loss: 0.6000 - val_acc: 0.5915
Epoch 43/100
50/50 - 10s - loss: 0.5943 - acc: 0.5958 - val_loss: 0.5948 - val_acc: 0.5903
Epoch 44/100
50/50 - 10s - loss: 0.5940 - acc: 0.5956 - val_loss: 0.5954 - val_acc: 0.5957
Epoch 45/100
50/50 - 10s - loss: 0.5941 - acc: 0.5967 - val_loss: 0.5944 - val_acc: 0.5980
Epoch 46/100
50/50 - 10s - loss: 0.5940 - acc: 0.5962 - val_loss: 0.5946 - val_acc: 0.6008
Epoch 47/100
50/50 - 10s - loss: 0.5940 - acc: 0.5975 - val_loss: 0.5942 - val_acc: 0.5950
Epoch 48/100
50/50 - 10s - loss: 0.5932 - acc: 0.5980 - val_loss: 0.5938 - val_acc: 0.6047
Epoch 49/100
50/50 - 10s - loss: 0.5941 - acc: 0.5976 - val_loss: 0.5938 - val_acc: 0.5956
Epoch 50/100
50/50 - 10s - loss: 0.5931 - acc: 0.5988 - val_loss: 0.5938 - val_acc: 0.6048
Epoch 51/100
50/50 - 10s - loss: 0.5947 - acc: 0.5973 - val_loss: 0.5954 - val_acc: 0.5674
Epoch 52/100
50/50 - 10s - loss: 0.5930 - acc: 0.5959 - val_loss: 0.5935 - val_acc: 0.5999
Epoch 53/100
50/50 - 10s - loss: 0.5929 - acc: 0.6003 - val_loss: 0.5936 - val_acc: 0.6027
Epoch 54/100
50/50 - 9s - loss: 0.5930 - acc: 0.6009 - val_loss: 0.5937 - val_acc: 0.5977
Epoch 55/100
50/50 - 9s - loss: 0.5928 - acc: 0.6011 - val_loss: 0.5933 - val_acc: 0.5998
Epoch 56/100
50/50 - 9s - loss: 0.5934 - acc: 0.6002 - val_loss: 0.5964 - val_acc: 0.6079
Epoch 57/100
50/50 - 10s - loss: 0.5926 - acc: 0.6004 - val_loss: 0.5931 - val_acc: 0.5945
Epoch 58/100
50/50 - 9s - loss: 0.5923 - acc: 0.6016 - val_loss: 0.5931 - val_acc: 0.6048
Epoch 59/100
50/50 - 9s - loss: 0.5927 - acc: 0.6026 - val_loss: 0.5937 - val_acc: 0.5981
Epoch 60/100
50/50 - 10s - loss: 0.5924 - acc: 0.6021 - val_loss: 0.5934 - val_acc: 0.6021
Epoch 61/100
50/50 - 10s - loss: 0.5923 - acc: 0.6025 - val_loss: 0.5937 - val_acc: 0.6048
Epoch 62/100
50/50 - 10s - loss: 0.5922 - acc: 0.6035 - val_loss: 0.5939 - val_acc: 0.5973
Epoch 63/100
50/50 - 9s - loss: 0.5922 - acc: 0.6029 - val_loss: 0.5925 - val_acc: 0.5995
Epoch 64/100
50/50 - 10s - loss: 0.5917 - acc: 0.6037 - val_loss: 0.5925 - val_acc: 0.6033
Epoch 65/100
50/50 - 10s - loss: 0.5923 - acc: 0.6016 - val_loss: 0.5922 - val_acc: 0.6092
Epoch 66/100
50/50 - 9s - loss: 0.5920 - acc: 0.6036 - val_loss: 0.5941 - val_acc: 0.6050
Epoch 67/100
50/50 - 9s - loss: 0.5915 - acc: 0.6039 - val_loss: 0.5920 - val_acc: 0.6051
Epoch 68/100
50/50 - 10s - loss: 0.5922 - acc: 0.6033 - val_loss: 0.5923 - val_acc: 0.5976
Epoch 69/100
50/50 - 10s - loss: 0.5916 - acc: 0.6042 - val_loss: 0.5922 - val_acc: 0.6031
Epoch 70/100
50/50 - 10s - loss: 0.5916 - acc: 0.6040 - val_loss: 0.5964 - val_acc: 0.5990
Epoch 71/100
50/50 - 10s - loss: 0.5913 - acc: 0.6037 - val_loss: 0.5918 - val_acc: 0.6027
Epoch 72/100
50/50 - 9s - loss: 0.5914 - acc: 0.6049 - val_loss: 0.5921 - val_acc: 0.6035
Epoch 73/100
50/50 - 9s - loss: 0.5916 - acc: 0.6044 - val_loss: 0.5917 - val_acc: 0.6064
Epoch 74/100
50/50 - 9s - loss: 0.5920 - acc: 0.6025 - val_loss: 0.5933 - val_acc: 0.6070
Epoch 75/100
50/50 - 10s - loss: 0.5909 - acc: 0.6031 - val_loss: 0.5917 - val_acc: 0.6058
Epoch 76/100
50/50 - 9s - loss: 0.5907 - acc: 0.6059 - val_loss: 0.5914 - val_acc: 0.6054
Epoch 77/100
50/50 - 10s - loss: 0.5924 - acc: 0.6016 - val_loss: 0.5915 - val_acc: 0.6095
Epoch 78/100
50/50 - 10s - loss: 0.5905 - acc: 0.6062 - val_loss: 0.5934 - val_acc: 0.6013
Epoch 79/100
50/50 - 9s - loss: 0.5907 - acc: 0.6057 - val_loss: 0.5918 - val_acc: 0.6097
Epoch 80/100
50/50 - 10s - loss: 0.5912 - acc: 0.6058 - val_loss: 0.5914 - val_acc: 0.6069
Epoch 81/100
50/50 - 10s - loss: 0.5910 - acc: 0.6059 - val_loss: 0.5912 - val_acc: 0.6080
Epoch 82/100
50/50 - 10s - loss: 0.5912 - acc: 0.6060 - val_loss: 0.5944 - val_acc: 0.6031
Epoch 83/100
50/50 - 10s - loss: 0.5916 - acc: 0.6022 - val_loss: 0.5912 - val_acc: 0.6056
Epoch 84/100
50/50 - 10s - loss: 0.5902 - acc: 0.6061 - val_loss: 0.5919 - val_acc: 0.6108
Epoch 85/100
50/50 - 9s - loss: 0.5906 - acc: 0.6066 - val_loss: 0.5910 - val_acc: 0.6091
Epoch 86/100
50/50 - 10s - loss: 0.5907 - acc: 0.6065 - val_loss: 0.5933 - val_acc: 0.6052
Epoch 87/100
50/50 - 10s - loss: 0.5903 - acc: 0.6065 - val_loss: 0.5910 - val_acc: 0.6073
Epoch 88/100
50/50 - 10s - loss: 0.5906 - acc: 0.6071 - val_loss: 0.5909 - val_acc: 0.6085
Epoch 89/100
50/50 - 10s - loss: 0.5906 - acc: 0.6066 - val_loss: 0.5914 - val_acc: 0.6001
Epoch 90/100
50/50 - 10s - loss: 0.5901 - acc: 0.6063 - val_loss: 0.5912 - val_acc: 0.6121
Epoch 91/100
50/50 - 10s - loss: 0.5900 - acc: 0.6074 - val_loss: 0.5910 - val_acc: 0.6076
Epoch 92/100
50/50 - 10s - loss: 0.5913 - acc: 0.6041 - val_loss: 0.5907 - val_acc: 0.6089
Epoch 93/100
50/50 - 10s - loss: 0.5897 - acc: 0.6076 - val_loss: 0.5925 - val_acc: 0.6038
Epoch 94/100
50/50 - 10s - loss: 0.5901 - acc: 0.6073 - val_loss: 0.5911 - val_acc: 0.6066
Epoch 95/100
50/50 - 10s - loss: 0.5904 - acc: 0.6076 - val_loss: 0.5905 - val_acc: 0.6095
Epoch 96/100
50/50 - 9s - loss: 0.5900 - acc: 0.6074 - val_loss: 0.5905 - val_acc: 0.6057
Epoch 97/100
50/50 - 10s - loss: 0.5900 - acc: 0.6076 - val_loss: 0.5905 - val_acc: 0.6097
Epoch 98/100
50/50 - 10s - loss: 0.5903 - acc: 0.6074 - val_loss: 0.5914 - val_acc: 0.5870
Epoch 99/100
50/50 - 10s - loss: 0.5898 - acc: 0.6053 - val_loss: 0.5905 - val_acc: 0.6086
Epoch 100/100
50/50 - 9s - loss: 0.5897 - acc: 0.6085 - val_loss: 0.5903 - val_acc: 0.6097

Finished training

Mean loss:  0.589271

Standard deviation:  0.071703516

Anomaly detection options:

 3 standard deviations from the mean training loss:  0.8043815568089485

Max training loss:  0.6922287

 98 th percentile of training loss:  0.6760045301914215

Using  n_percentile  method for anomaly detection
Train CIFAR10 shape:  (50000, 32, 32, 3)
Train CIFAR10 anomaly detection rate:  2.0 %

Validation CIFAR10 shape:  (10000, 32, 32, 3)
Validation CIFAR10 anomaly detection rate:  1.9900000000000002 %
Reading in CIFAR100 again

Split into 2, remove pickup truck from 1 half and leave it in in the other half

Removing pickup truck from CIFAR 100

With truck shape :  (25000, 32, 32, 3)

With truck anomaly detection rate:  1.8386809989493251 %

Without truck shape :  (24746, 32, 32, 3)

Without truck anomaly detection rate:  1.7093671704517903 %
